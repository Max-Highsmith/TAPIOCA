{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import optuna\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "import yaml\n",
    "\n",
    "from Data.Drosophilla.FlyDataMod import FlyDataModule\n",
    "from IPython.core.debugger import set_trace\n",
    "from Models import LinearRegression as lrg\n",
    "from torch import nn as nn\n",
    "from Utils import callbacks as cb\n",
    "from Utils import evaluations as ev\n",
    "from Utils import HyperParams as hp\n",
    "from Utils import loggers as lg\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runLR_Exp(\n",
    "    trial,\n",
    "    lr,\n",
    "    batch_size,\n",
    "    label_type,\n",
    "    label_val,\n",
    "    hasRidge,\n",
    "    hasLasso,\n",
    "    root_dir,\n",
    "    ):\n",
    "    logger  = lg.DictLogger(trial.number,\n",
    "                           root_dir)\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=1,\n",
    "        logger=logger,\n",
    "        max_epochs=50,\n",
    "        callbacks=[cb.getcb()],\n",
    "        default_root_dir=root_dir)\n",
    "    \n",
    "    #\"Experiments/Table_4_Linear_Regression_HP_Tuning\")\n",
    "\n",
    "    dm = FlyDataModule(cell_line=\"S2\",\n",
    "                  data_win_radius=5,\n",
    "                  batch_size=batch_size,\n",
    "                  label_type=label_type,\n",
    "                  label_val=label_val)\n",
    "    dm.setup()\n",
    "\n",
    "    hparams={'cell_line':\"S2\",\n",
    "            \"data_win_radius\":5,\n",
    "            \"label_type\":label_type,\n",
    "            \"batch_size\":batch_size}\n",
    "    model_linear  = lrg.LinearRegressionModule(\n",
    "        inputSize=29,\n",
    "        outputSize=1,\n",
    "        hasRidge=hasRidge,\n",
    "        hasLasso=hasLasso,\n",
    "        lr=lr,\n",
    "        hparams=hparams)\n",
    "    model_linear.cuda()\n",
    "\n",
    "    trainer.fit(model_linear, dm)\n",
    "    score = logger.metrics[-1]['val weighted mse loss']\n",
    "    if np.isnan(score):\n",
    "        score = 9999999\n",
    "    return score\n",
    "\n",
    "def objective(trial):\n",
    "    lr = trial.suggest_categorical(\"lr\", [1e-5, 1e-4, 1e-3, 1e-2, 1e-1])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [1, 4, 16, 64])\n",
    "    return runLR_Exp(\n",
    "        trial=trial,\n",
    "        lr=lr,\n",
    "        batch_size=batch_size,\n",
    "        label_type=label_type,\n",
    "        label_val=label_val,\n",
    "        hasRidge=hasRidge,\n",
    "        hasLasso=hasLasso,\n",
    "        root_dir=root_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table 4 linear regress lambda\n",
    "label_type  = \"gamma\"\n",
    "label_val = 0\n",
    "for hasLasso, hasRidge in [(False, False),\n",
    "                           (True, True),\n",
    "                           (True, False),\n",
    "                           (False, True)]:\n",
    "    if not os.path.isdir(\"Experiments/Table_4_Linear_Regression_Tunning\"):\n",
    "        os.mkdir(\"Experiments/Table_4_Linear_Regression_Tunning\")\n",
    "    root_dir = \"Experiments/Table_4_Linear_Regression_Tunning/\"+label_type+\"_\"+str(label_val)+\"_R\"+str(hasRidge)+\"_L\"+str(hasLasso)\n",
    "    if not os.path.isdir(root_dir):\n",
    "        os.mkdir(root_dir)\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=10)\n",
    "    hp.save_hyperparams(root_dir,\n",
    "                    study.best_trial.number)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table 5 linear regress lambda\n",
    "label_type  = \"insulation\"\n",
    "label_val = 3\n",
    "for hasLasso, hasRidge in [(False, False),\n",
    "                           (True, True),\n",
    "                           (True, False),\n",
    "                           (False, True)]:\n",
    "    root_dir = \"Experiments/Table_5_Linear_Regression_Tunning/\"+label_type+\"_\"+str(label_val)+\"_R\"+str(hasRidge)+\"_L\"+str(hasLasso)\n",
    "    if not os.path.isdir(\"Experiments/Table_5_Linear_Regression_Tunning/\"):\n",
    "        os.mkdir(\"Experiments/Table_5_Linear_Regression_Tunning/\")\n",
    "    if not os.path.isdir(root_dir):\n",
    "        os.mkdir(root_dir)\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=10)\n",
    "    hp.save_hyperparams(root_dir,\n",
    "                    study.best_trial.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Table 6 linear regress lambda\n",
    "label_type  = \"directionality\"\n",
    "label_val = 10\n",
    "for hasLasso, hasRidge in [(False, False),\n",
    "                           (True, True),\n",
    "                           (True, False),\n",
    "                           (False, True)]:\n",
    "    root_dir = \"Experiments/Table_6_Linear_Regression_Tunning/\"+label_type+\"_\"+str(label_val)+\"_R\"+str(hasRidge)+\"_L\"+str(hasLasso)\n",
    "    if not os.path.isdir(\"Experiments/Table_6_Linear_Regression_Tunning/\"):\n",
    "        os.mkdir(\"Experiments/Table_6_Linear_Regression_Tunning/\")\n",
    "    if not os.path.isdir(root_dir):\n",
    "        os.mkdir(root_dir)\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=10)\n",
    "    hp.save_hyperparams(root_dir,\n",
    "                    study.best_trial.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = FlyDataModule(cell_line=\"S2\",\n",
    "                  data_win_radius=5,\n",
    "                  batch_size=1,\n",
    "                  label_type='insulation',\n",
    "                  label_val=10)\n",
    "dm.setup()\n",
    "layer_weights = glob.glob(\"Experiments/Table_5_Linear_Regression_Tunning/insulation_10_RFalse_LFalse/optuna/version_0/checkpoints/*\")[0]\n",
    "model         = lrg.LinearRegressionModule.load_from_checkpoint(layer_weights).to(\"cuda:0\")\n",
    "ev.createPlot(model, dm, \"train\", \"idk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display Table 4\n",
    "label_type  = \"gamma\"\n",
    "label_val = 0\n",
    "hasRidge   = False\n",
    "hasLasso   = False\n",
    "\n",
    "\n",
    "\n",
    "vals = []\n",
    "for hadRidge, hasLasso in [(True, True),\n",
    "                          (True, False),\n",
    "                          (False, True),\n",
    "                          (False, False)]:\n",
    "    root_dir = \"Experiments/Table_4_Linear_Regression_Tunning/\"+label_type+\"_\"+str(label_val)+\"_R\"+str(hasRidge)+\"_L\"+str(hasLasso)\n",
    "    dm = FlyDataModule(cell_line=\"S2\",\n",
    "                  data_win_radius=5,\n",
    "                  batch_size=1,\n",
    "                  label_type=label_type,\n",
    "                  label_val=label_val)\n",
    "    dm.setup()\n",
    "    exps = sorted(glob.glob(root_dir+\"/optuna/*\"))\n",
    "    for e, exp in enumerate(exps):\n",
    "        layer_weights = glob.glob(exp+\"/checkpoints/*\")[0]\n",
    "        hparams       = yaml.full_load(open(glob.glob(exp+\"/hparams.yaml\")[0],'r'))\n",
    "        model = lrg.LinearRegressionModule.load_from_checkpoint(layer_weights).to(\"cuda:0\")\n",
    "        row = []\n",
    "        row.append(hparams['lr'])\n",
    "        row.append(hparams['hparams']['batch_size'])\n",
    "        mm  = ev.getModelMetrics(model, dm, 'val').values()\n",
    "        fmm = list(map(lambda x: \"{:.2f}\".format(x), mm))\n",
    "        row.extend(fmm)\n",
    "        vals.append(row)\n",
    "        \n",
    "\n",
    "        \n",
    "cols=['lr','b_sz','val_mse','val_mae','val_r2','val_pcc','val_spc']\n",
    "fig, ax = plt.subplots(1, figsize=(20,20))\n",
    "table   = ax.table(vals,\n",
    "                cellLoc=\"center\",\n",
    "                colLabels=cols,\n",
    "                rowLabels=list(range(0,len(vals))))\n",
    "\n",
    "table.set_fontsize(14)\n",
    "ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "#to csv\n",
    "# TODO problem, right now the results are split by regression types\n",
    "import pandas as pd\n",
    "ar_val   = np.array(vals)\n",
    "ar_col   = np.expand_dims(np.array(cols),0)\n",
    "csv_data = np.vstack((ar_col, ar_val))\n",
    "pd.DataFrame(csv_data).to_csv(\"Experiments/Table_4_Linear_Regression_Tunning/Sup_4_Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#display Table 5\n",
    "label_type  = \"insulation\"\n",
    "label_val = 3\n",
    "hasRidge   = False\n",
    "hasLasso   = False\n",
    "\n",
    "vals = []\n",
    "for hadRidge, hasLasso in [(True, True),\n",
    "                          (True, False),\n",
    "                          (False, True),\n",
    "                          (False, False)]:\n",
    "    root_dir = \"Experiments/Table_5_Linear_Regression_Tunning/\"+label_type+\"_\"+str(label_val)+\"_R\"+str(hasRidge)+\"_L\"+str(hasLasso)\n",
    "    print(root_dir)\n",
    "    dm = FlyDataModule(cell_line=\"S2\",\n",
    "                  data_win_radius=5,\n",
    "                  batch_size=1,\n",
    "                  label_type=label_type,\n",
    "                  label_val=label_val)\n",
    "    dm.setup()\n",
    "    exps = sorted(glob.glob(root_dir+\"/optuna/*\"))\n",
    "    for e, exp in enumerate(exps):\n",
    "        print(e)\n",
    "        layer_weights = glob.glob(exp+\"/checkpoints/*\")[0]\n",
    "        hparams       = yaml.full_load(open(glob.glob(exp+\"/hparams.yaml\")[0],'r'))\n",
    "        model = lrg.LinearRegressionModule.load_from_checkpoint(layer_weights).to(\"cuda:0\")\n",
    "        row = []\n",
    "        row.append(hparams['lr'])\n",
    "        row.append(hparams['hparams']['batch_size'])\n",
    "        mm  = ev.getModelMetrics(model, dm, 'val').values()\n",
    "        fmm = list(map(lambda x: \"{:.2f}\".format(x), mm))\n",
    "        row.extend(fmm)\n",
    "        vals.append(row)\n",
    "        \n",
    "\n",
    "        \n",
    "cols=['lr','b_sz','val_mse','val_mae','val_r2','val_pcc','val_spc']\n",
    "fig, ax = plt.subplots(1, figsize=(20,20))\n",
    "table   = ax.table(vals,\n",
    "                cellLoc=\"center\",\n",
    "                colLabels=cols,\n",
    "                rowLabels=list(range(0,len(vals))))\n",
    "\n",
    "table.set_fontsize(14)\n",
    "ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "#to csv\n",
    "# TODO problem, right now the results are split by regression types\n",
    "import pandas as pd\n",
    "ar_val   = np.array(vals)\n",
    "ar_col   = np.expand_dims(np.array(cols),0)\n",
    "csv_data = np.vstack((ar_col, ar_val))\n",
    "pd.DataFrame(csv_data).to_csv(\"Experiments/Table_5_Linear_Regression_Tunning/Sup_5_Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display Table 6\n",
    "label_type  = \"directionality\"\n",
    "label_val = 10\n",
    "hasRidge   = False\n",
    "hasLasso   = False\n",
    "\n",
    "\n",
    "\n",
    "vals = []\n",
    "for hadRidge, hasLasso in [(True, True),\n",
    "                          (True, False),\n",
    "                          (False, True),\n",
    "                          (False, False)]:\n",
    "    root_dir = \"Experiments/Table_6_Linear_Regression_Tunning/\"+label_type+\"_\"+str(label_val)+\"_R\"+str(hasRidge)+\"_L\"+str(hasLasso)\n",
    "    dm = FlyDataModule(cell_line=\"S2\",\n",
    "                  data_win_radius=5,\n",
    "                  batch_size=1,\n",
    "                  label_type=label_type,\n",
    "                  label_val=label_val)\n",
    "    dm.setup()\n",
    "    exps = sorted(glob.glob(root_dir+\"/optuna/*\"))\n",
    "    for e, exp in enumerate(exps):\n",
    "        layer_weights = glob.glob(exp+\"/checkpoints/*\")[0]\n",
    "        hparams       = yaml.full_load(open(glob.glob(exp+\"/hparams.yaml\")[0],'r'))\n",
    "        model = lrg.LinearRegressionModule.load_from_checkpoint(layer_weights).to(\"cuda:0\")\n",
    "        row = []\n",
    "        row.append(hparams['lr'])\n",
    "        row.append(hparams['hparams']['batch_size'])\n",
    "        mm  = ev.getModelMetrics(model, dm, 'val').values()\n",
    "        fmm = list(map(lambda x: \"{:.2f}\".format(x), mm))\n",
    "        row.extend(fmm)\n",
    "        vals.append(row)\n",
    "        \n",
    "\n",
    "        \n",
    "cols=['lr','b_sz','val_mse','val_mae','val_r2','val_pcc','val_spc']\n",
    "fig, ax = plt.subplots(1, figsize=(20,20))\n",
    "table   = ax.table(vals,\n",
    "                cellLoc=\"center\",\n",
    "                colLabels=cols,\n",
    "                rowLabels=list(range(0,len(vals))))\n",
    "\n",
    "table.set_fontsize(14)\n",
    "ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "#to csv\n",
    "# TODO problem, right now the results are split by regression types\n",
    "import pandas as pd\n",
    "ar_val   = np.array(vals)\n",
    "ar_col   = np.expand_dims(np.array(cols),0)\n",
    "csv_data = np.vstack((ar_col, ar_val))\n",
    "pd.DataFrame(csv_data).to_csv(\"Experiments/Table_6_Linear_Regression_Tunning/Sup_6_Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = FlyDataModule(cell_line=\"S2\",\n",
    "                  data_win_radius=5,\n",
    "                  batch_size=1,\n",
    "                  label_type=\"insulation\",\n",
    "                  label_val=10)\n",
    "dm.setup()\n",
    "path=\"/home/heracles/Documents/Professional/Research/Honeydew/Experiments/Table_4_Linear_Regression_Tunning/insulation_10_RFalse_LFalse/optuna/version_5/checkpoints/epoch=49-step=197949.ckpt\"\n",
    "model = lrg.LinearRegressionModule.load_from_checkpoint(path).cuda()\n",
    "print(ev.getModelMetrics(model, dm, 'train'))\n",
    "ev.createPlot(model, dm, \"train\",\"l.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to csv\n",
    "# TODO problem, right now the results are split by regression types\n",
    "import pandas as pd\n",
    "ar_val   = np.array(vals)\n",
    "ar_col   = np.expand_dims(np.array(cols),0)\n",
    "csv_data = np.vstack((ar_col, ar_val))\n",
    "pd.DataFrame(csv_data).to_csv(\"Experiments/Table_4_Linear_Regression_Tunning/Sup_4_Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
