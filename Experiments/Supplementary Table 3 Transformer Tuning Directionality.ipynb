{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import optuna\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "import yaml\n",
    "\n",
    "from Data.Drosophilla.FlyDataMod import FlyDataModule\n",
    "from IPython.core.debugger import set_trace\n",
    "from Models import Transformer as tr\n",
    "from torch import nn as nn\n",
    "from Utils import callbacks as cb\n",
    "from Utils import evaluations as ev\n",
    "from Utils import HyperParams as hp\n",
    "from Utils import loggers as lg\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTransformer_Exp(\n",
    "    trial,\n",
    "    label_type,\n",
    "    label_val,\n",
    "    lr,\n",
    "    batch_size,\n",
    "    ntoken,\n",
    "    ninp,\n",
    "    nhead,\n",
    "    nhid,\n",
    "    nlayers,\n",
    "    dropout,\n",
    "    data_win_radius=5):\n",
    "    logger = lg.DictLogger(trial.number,\n",
    "                          root_dir)\n",
    "    trainer = pl.Trainer(\n",
    "            gpus=1,\n",
    "            logger=logger,\n",
    "            max_epochs=50,\n",
    "            callbacks=[cb.getcb()],\n",
    "            default_root_dir=root_dir)\n",
    "    dm      = FlyDataModule(cell_line=\"S2\",\n",
    "                           data_win_radius=data_win_radius,\n",
    "                           batch_size=batch_size,\n",
    "                           label_type=label_type,\n",
    "                           label_val=label_val)\n",
    "    dm.setup()\n",
    "    \n",
    "    hparams={'cell_line':'S2',\n",
    "            \"data_win_radius\":data_win_radius,\n",
    "            \"label_type\":label_type,\n",
    "            \"batch_size\":batch_size}\n",
    "    \n",
    "    model_trans = tr.TransformerModule(\n",
    "            ntoken=ntoken,\n",
    "            ninp=ninp,\n",
    "            nhead=nhead,\n",
    "            nhid=nhid,\n",
    "            nlayers=nlayers,\n",
    "            dropout=dropout,\n",
    "            loss_type=\"mse\",\n",
    "            lr=lr,\n",
    "            hparams=hparams)\n",
    "    model_trans.cuda()\n",
    "    trainer.fit(model_trans, dm)\n",
    "    score = logger.metrics[-1]['val weighted mse loss']\n",
    "    if np.isnan(score):\n",
    "        score=9999999\n",
    "    return score\n",
    "\n",
    "def objective(trial):\n",
    "    lr          = trial.suggest_categorical(\"lr\", [1e-4, 1e-3, 1e-2, 1e-1])\n",
    "    batch_size  = trial.suggest_categorical(\"batch_size\", [1,4,16,64]) \n",
    "    num_layers  = trial.suggest_categorical(\"num_layers\", [1,2,3,4,5,6]) \n",
    "    dropout     = trial.suggest_categorical(\"dropout\", [0,0.3,0.5,0.7,0.9]) \n",
    "    nhid        = trial.suggest_categorical(\"nhid\", [512,1024,2048])\n",
    "    print(lr, batch_size, num_layers, dropout)\n",
    "    return runTransformer_Exp(\n",
    "            trial=trial,\n",
    "            label_type=label_type,\n",
    "            label_val=label_val,\n",
    "            lr=lr,\n",
    "            batch_size=batch_size,\n",
    "            ntoken=1,\n",
    "            ninp=29,\n",
    "            nhead=7,\n",
    "            nhid=nhid,\n",
    "            nlayers=num_layers,\n",
    "            dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_type = \"directionality\"\n",
    "label_val  = 10\n",
    "root_dir   = \"Experiments/Table_3_Transformer_Tunning_Directionality\"\n",
    "if not os.path.isdir(root_dir):\n",
    "    os.mkdir(root_dir)\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "hp.save_hyperparams(root_dir,\n",
    "                    study.best_trial.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_type = \"directionality\"\n",
    "label_val  = 10\n",
    "root_dir   = \"Experiments/Table_3_Transformer_Tunning_Directionality\"\n",
    "dm         = FlyDataModule(cell_line=\"S2\",\n",
    "                          data_win_radius=5,\n",
    "                          batch_size=1,\n",
    "                          label_type=label_type,\n",
    "                          label_val=label_val)\n",
    "dm.setup()\n",
    "vals=[]\n",
    "\n",
    "exps = sorted(glob.glob(root_dir+\"/optuna/*\"))\n",
    "for e, exp in enumerate(exps):\n",
    "    layer_weights = glob.glob(exp+\"/checkpoints/*\")[0]\n",
    "    hparams       = yaml.full_load(open(glob.glob(exp+\"/hparams.yaml\")[0]))\n",
    "    model         = tr.TransformerModule.load_from_checkpoint(layer_weights).to(\"cuda:0\")\n",
    "    row           = []\n",
    "    row.append(hparams['lr'])\n",
    "    row.append(hparams['hparams']['batch_size'])\n",
    "    row.append(hparams['nlayers'])\n",
    "    row.append(hparams['dropout'])\n",
    "    mm            = ev.getModelMetrics(model, dm, 'val').values()\n",
    "    fmm           = list(map(lambda x: \"{:.2f}\".format(x), mm ))\n",
    "    row.extend(fmm)\n",
    "    vals.append(row)\n",
    "cols = ['lr','b_sz', '# lyrs', 'dropout','val_mse','val_mae','val_r2','val_pcc','val_spc']\n",
    "fig, ax = plt.subplots(1, figsize=(20,20))\n",
    "table   = ax.table(vals,\n",
    "                  cellLoc=\"center\",\n",
    "                  colLabels=cols,\n",
    "                  rowLabels=list(range(0, len(exps))))\n",
    "table.set_fontsize(14)\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = FlyDataModule(cell_line=\"S2\",\n",
    "                  data_win_radius=5,\n",
    "                  batch_size=1,\n",
    "                  label_type=\"directionality\",\n",
    "                  label_val=10)\n",
    "dm.setup()\n",
    "layer_weights = glob.glob(\"Experiments/Table_3_Transformer_Tunning_Directionality/optuna/version_5/checkpoints/*\")[0]\n",
    "print(layer_weights)\n",
    "model         = tr.TransformerModule.load_from_checkpoint(layer_weights).to(\"cuda:0\")\n",
    "#ev.createPlot(model, dm, \"train\", \"idk\")\n",
    "for b, batch in enumerate(dm.train_dataloader()):\n",
    "    feature, label = batch\n",
    "    feature = feature.to('cuda:0').float()\n",
    "    label   = label.to('cuda:0').float()\n",
    "    output  = model(feature)\n",
    "    output  = output.squeeze()\n",
    "    label   = label.squeeze()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(label.cpu())\n",
    "    ax.plot(output.detach().cpu())\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = FlyDataModule(cell_line=\"S2\",\n",
    "                  data_win_radius=5,\n",
    "                  batch_size=1,\n",
    "                  label_type=\"directionality\",\n",
    "                  label_val=10)\n",
    "dm.setup()\n",
    "layer_weights = glob.glob(\"Experiments/Table_3_Transformer_Tunning_Directionality/optuna/version_5/checkpoints/*\")[0]\n",
    "print(layer_weights)\n",
    "model         = tr.TransformerModule.load_from_checkpoint(layer_weights).to(\"cuda:0\")\n",
    "ev.createPlot(model, dm, \"test\", \"idk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to csv\n",
    "import pandas as pd\n",
    "ar_val   = np.array(vals)\n",
    "ar_col   = np.expand_dims(np.array(cols),0)\n",
    "csv_data = np.vstack((ar_col, ar_val))\n",
    "pd.DataFrame(csv_data).to_csv(\"Experiments/Table_3_Transformer_Tunning_Directionality/Sup_3_Results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
