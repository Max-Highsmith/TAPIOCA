{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import optuna\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "import yaml\n",
    "\n",
    "from Data.Drosophilla.FlyDataMod import FlyDataModule\n",
    "from IPython.core.debugger import set_trace\n",
    "from Models import BiLSTM as bi\n",
    "from torch import nn as nn\n",
    "from Utils import callbacks as cb\n",
    "from Utils import evaluations as ev\n",
    "from Utils import HyperParams as hp\n",
    "from Utils import loggers as lg\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runBiLSTM_Exp(\n",
    "    trial,\n",
    "    label_type,\n",
    "    label_val,\n",
    "    lr,\n",
    "    batch_size,\n",
    "    num_layers,\n",
    "    hidden_size,\n",
    "    dropout,\n",
    "    bias):\n",
    "    logger = lg.DictLogger(trial.number,\n",
    "                          root_dir)\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=1,\n",
    "        logger=logger,\n",
    "        max_epochs=50,\n",
    "        callbacks=[cb.getcb()],\n",
    "        default_root_dir=root_dir)\n",
    "    \n",
    "    dm = FlyDataModule(cell_line=\"S2\",\n",
    "                     data_win_radius=5,\n",
    "                     batch_size=batch_size,\n",
    "                     label_type=label_type,\n",
    "                     label_val=label_val)\n",
    "    dm.setup()\n",
    "    \n",
    "    hparams = {'cell_line':\"S2\",\n",
    "              \"data_win_radius\":5,\n",
    "              \"label_type\":label_type,\n",
    "              \"batch_size\":batch_size}\n",
    "    \n",
    "    model_bilstm = bi.BiLSTMModule(\n",
    "                    input_size=29,\n",
    "                    hidden_size=hidden_size,\n",
    "                    num_layers=num_layers,\n",
    "                    dropout=dropout,\n",
    "                    bias=bias,\n",
    "                    lr=lr,\n",
    "                    hparams=hparams\n",
    "                )\n",
    "    model_bilstm.cuda()\n",
    "    \n",
    "    trainer.fit(model_bilstm, dm)\n",
    "    score = logger.metrics[-1]['val weighted mse loss']\n",
    "    if np.isnan(score):\n",
    "        score = 99999999\n",
    "    return score\n",
    "\n",
    "def objective(trial):\n",
    "    lr          = trial.suggest_categorical(\"lr\", [1e-5, 1e-4, 1e-3, 1e-2, 1e-1])\n",
    "    batch_size  = trial.suggest_categorical(\"batch_size\", [1,4,16,64])\n",
    "    num_layers  = trial.suggest_categorical(\"num_layers\", [1,2,3,4,5,6])\n",
    "    hidden_size = trial.suggest_categorical(\"hidden_size\", [64])\n",
    "    dropout     = trial.suggest_categorical(\"dropout\", [0, 0.1, 0.2, 0.3])\n",
    "    bias        = trial.suggest_categorical(\"bias\", [True, False])\n",
    "    print(lr, batch_size, num_layers, hidden_size, dropout, bias)\n",
    "    return runBiLSTM_Exp(\n",
    "        trial=trial,\n",
    "        label_type=label_type,\n",
    "        label_val=label_val,\n",
    "        lr=lr,\n",
    "        batch_size=batch_size,\n",
    "        num_layers=num_layers,\n",
    "        hidden_size=hidden_size,\n",
    "        dropout=dropout,\n",
    "        bias=bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_type = \"insulation\"\n",
    "label_val  = 10\n",
    "root_dir   = \"Experiments/Table_8_LSTM_Tunning_Insulation\"\n",
    "if not os.path.isdir(root_dir):\n",
    "    os.mkdir(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_type = \"insulation\"\n",
    "label_val  = 10\n",
    "root_dir   = \"Experiments/Table_8_LSTM_Tunning_Insulation\"\n",
    "if not os.path.isdir(root_dir):\n",
    "    os.mkdir(root_dir)\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "hp.save_hyperparams(root_dir,\n",
    "                   study.best_trial.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display table 8\n",
    "label_type = \"insulation\"\n",
    "label_val  = 10\n",
    "dm         = FlyDataModule(cell_line=\"S2\",\n",
    "                          data_win_radius=5,\n",
    "                          batch_size=1,\n",
    "                          label_type=label_type,\n",
    "                          label_val=label_val)\n",
    "dm.setup()\n",
    "vals = []\n",
    "\n",
    "exps = sorted(glob.glob(root_dir+\"/optuna/*\"))\n",
    "for e, exp in enumerate(exps):\n",
    "    layer_weights = glob.glob(exp+\"/checkpoints/*\")[0]\n",
    "    hparams       = yaml.full_load(open(glob.glob(exp+\"/hparams.yaml\")[0], 'r'))\n",
    "    model         = bi.BiLSTMModule.load_from_checkpoint(layer_weights).to(\"cuda:0\")\n",
    "    row           = []\n",
    "    row.append(hparams['lr'])\n",
    "    row.append(hparams['hparams']['batch_size'])\n",
    "    row.append(hparams['num_layers'])\n",
    "    row.append(hparams['dropout'])\n",
    "    row.append(hparams['bias'])\n",
    "    mm            = ev.getModelMetrics(model, dm, 'val').values()\n",
    "    fmm           = list(map(lambda x: \"{:.2f}\".format(x), mm ))\n",
    "    row.extend(fmm)\n",
    "    vals.append(row)\n",
    "cols = ['lr','b_sz', '# lyrs', 'dropout','bias','val_mse','val_mae','val_r2','val_pcc','val_spc']\n",
    "fig, ax = plt.subplots(1, figsize=(20,20))\n",
    "table   = ax.table(vals,\n",
    "                  cellLoc=\"center\",\n",
    "                  colLabels=cols,\n",
    "                  rowLabels=list(range(0, len(exps))))\n",
    "table.set_fontsize(14)\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = FlyDataModule(cell_line=\"S2\",\n",
    "                  data_win_radius=5,\n",
    "                  batch_size=1,\n",
    "                  label_type=\"insulation\",\n",
    "                  label_val=10)\n",
    "dm.setup()\n",
    "layer_weights = glob.glob(\"Experiments/Table_8_LSTM_Tunning_Insulation/optuna/version_6/checkpoints/*\")[0]\n",
    "print(layer_weights)\n",
    "model         = bi.BiLSTMModule.load_from_checkpoint(layer_weights).to(\"cuda:0\")\n",
    "ev.createPlot(model, dm, \"train\", \"idk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to csv\n",
    "import pandas as pd\n",
    "ar_val   = np.array(vals)\n",
    "ar_col   = np.expand_dims(np.array(cols),0)\n",
    "csv_data = np.vstack((ar_col, ar_val))\n",
    "pd.DataFrame(csv_data).to_csv(\"Experiments/Table_8_LSTM_Tunning_Insulation/Sup_8_Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
